{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script content\n",
    "\n",
    "## Here we train a 20 topics model on all of the data. The goal is to build a recommendation engine and we do that as follows.\n",
    "\n",
    "### 1) Extract topics distribution per document from the model object. To compute expertise on topics we sum these probabilities up to folder level over all outbox emails (now it may be clear why we removed forward emails texts). Call this value OUT_sum (derived per folder and topic ).\n",
    "\n",
    "### 2) To compute level s of interest in a topic we first sum over all inbox mails, at folder topic level. Call this column IN_sum.\n",
    "\n",
    "### 3) We consider OUT_sum to be a good measure of knowledge on a topic, as it accounts for both the odds that an email is indeed about a topic as well as how often folder owner speaks about this topic.\n",
    "\n",
    "## 4) Interest in a topic is (considering recommendation engine as the goal!) is measured by the ration OUT_sum/IN_sum. This measure also accounts for situations where expert talks to other experts, thus needs no mentor there.  \n",
    "\n",
    "### 5) For a mentor and mentee pair of executives (i,j) (ordered pair!) with corresponding values for a topic t, we then compute the following metric\n",
    "\n",
    "#               M(t,i,j):=OUT_sum(i,t)* ((OUT_sum(j,t) + beta)/(IN_sum(j,t) + beta))\n",
    "\n",
    "### as our measure of the goodness of the match for topic t and pair (I,j). Summing over all topics gives\n",
    "\n",
    "# M(i,j)=Sum_{i,j} M(t,i,j)\n",
    "\n",
    "### as overall measure of match. This is in fact an inner product and in is high when the mentor and mentee have both high values in many topics.\n",
    "\n",
    "## Our recommendation engine will propose per mentor 3 mentees with maximal values of M(i,.). Choice for 3 is bit arbitrary and implementing in a business would require considering further specifics to come from the stakeholders.\n",
    "\n",
    "# Notice that we match based on expertise  and preference levels as well as interest in receiving mentorship (according to our interpretation) over all topics jointly!!!\n",
    "#### Off course further analysis will yield what the actual topics per pair are that really matter.\n",
    "\n",
    "# How to test this unsupervised engine?\n",
    "\n",
    "## Well a complex machine like  car or plane is not tested by a single test for a good reason. Therefore our model which consists of various steps also need to be addressed in various ways. LDA topics model has already been tested thus we only need to test the method developed here. We propose the following three metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1\n",
    "\n",
    "### We randomly assign emails to folders, with distribution as observed across folders. That is we sample folder ids with probability equal to proportion of emails in it (in and outbox). \n",
    "### We then compute the above defined metrics and at the end sum over all mentors  + 3 mentees with highest matching score.\n",
    "\n",
    "### Repeating this say 5000 times will give us a distribution and we are interested in the p-value of observing what we observed. If it is highly unlikely (in the tail) then that obviously votes in favor of our matching system being meaningful. Such a permutation test type of approach is often used in applied statistics---say determining whether some quantity (height etc) in one group is significantly different from that of the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "\n",
    "### Instead of picking top three mentees per mentor we sample three random mentees to see where about is our best choice in the distribution generated in this way. That is we estimate p-value of the distribution generated by randomly assigning mentees, but with same metric as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3\n",
    "\n",
    "### Instead of resigning emails to folders we pick random pairs of mentors as well as mentees (without replacement so that each mentor is in exactly one pair and same holds at the mentees side), and in addition we pick at random a percentage of topics (say 50% of topics) and swap the corresponding OUT_sum (mentors side ) and IN_sum values (mentees side), and then re-compute everything up to the final score per mentor mentee combination, pick the top three values for each mentor and sum all of those over all mentors.. \n",
    "\n",
    "### Here too we wish to observe that out true value is very high up in that distribution. That is if one reassigns these preferences in an arbitrary way we get much lower top scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us now get to coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned email texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cPickle \n",
    "matrixpath = file('/notebooks/LDA models and data/Data Frames and lists/text_term_matrix_clean.pkl', 'rb')\n",
    "text_term_matrix=cPickle.load(matrixpath )\n",
    "\n",
    "matrix0path = file('/notebooks/LDA models and data/Data Frames and lists/text_term_matrix_clean.pkl', 'rb')\n",
    "text_clean=cPickle.load(matrix0path)\n",
    "\n",
    "dictfilepath=file('/notebooks/LDA models and data/Data Frames and lists/Dictionary.pkl', 'rb')\n",
    "Dictionary=cPickle.load(dictfilepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import ldamodel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a LDA model with 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel_20 =gensim.models.ldamulticore.LdaMulticore(corpus=text_term_matrix, num_topics=20, id2word=Dictionary, workers=10,\\\n",
    "chunksize=2000, passes=1, batch=False, alpha='symmetric', eta=None, decay=0.5, offset=1.0,\\\n",
    "eval_every=10, iterations=50, gamma_threshold=0.001, random_state=None, minimum_probability=0.01,\\\n",
    "minimum_phi_value=0.01, per_word_topics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect inferred document topic probabilities from the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import ldamodel\n",
    "doc_topic_prob=[]\n",
    "for bowplus in text_term_matrix0:\n",
    "    doc_topic_prob.append([bowplus[0] ,bowplus[1] ,ldamodel_20.get_document_topics(bowplus[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('/notebooks/LDA models and data/Data Frames and lists/doc_topic_prob.pkl', 'wb') as pickle_file:\n",
    "    cPickle.dump(obj=doc_topic_prob, file=pickle_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack doc topic probabilities list to an array and then data frame with columns: \n",
    "\n",
    "## 'dirpath', 'inout_id','emailid', 'topicid', 'prob'\n",
    "\n",
    "### That file is sufficient to build and evaluate our recommendation engine as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "resarray=np.array(['dirpath', 'inout_id','emailid' ,'topicid', 'prob'], dtype=np.dtype('a16'), ndmin=2)\n",
    "for bowplus in doc_topic_prob:\n",
    "    if k % 10000==0:\n",
    "        print k\n",
    "    comunalia=np.array([bowplus[0],bowplus[1],str(k)], ndmin=2)\n",
    "    probs =np.array([list(i) for i in bowplus[2]], dtype=np.dtype('a16'))\n",
    "    rep=len(bowplus[2])\n",
    "    comunalia_rep=np.repeat(a=comunalia, repeats=rep, axis=0)\n",
    "    thisbow=np.ma.concatenate([comunalia_rep, probs], axis=-1)\n",
    "    resarray=np.ma.concatenate([resarray, thisbow], axis=0)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running of the code lines in the previous cell took very long (app. 4 hours) and without a doubt this can be handled more efficiently. However due to time constraints we shall leave it as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save!!\n",
    "pickle_file=file('/notebooks/LDA models and data/Data Frames and lists/resarray.pkl', 'wb')\n",
    "cPickle.dump(obj=resarray, file=pickle_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outpout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data =\n",
       " [['dirpath' 'inout_id' 'emailid' 'topicid' 'prob']\n",
       " ['hain-m' '0' '0' '0' '0.0250000000244']\n",
       " ['hain-m' '0' '0' '1' '0.0250000000762']\n",
       " ['hain-m' '0' '0' '2' '0.0250000000577']\n",
       " ['hain-m' '0' '0' '3' '0.0250000000608']\n",
       " ['hain-m' '0' '0' '4' '0.0250000000233']\n",
       " ['hain-m' '0' '0' '5' '0.0250000002241']\n",
       " ['hain-m' '0' '0' '6' '0.0250000000178']\n",
       " ['hain-m' '0' '0' '7' '0.0250000000259']\n",
       " ['hain-m' '0' '0' '8' '0.025000000075']],\n",
       "             mask =\n",
       " False,\n",
       "       fill_value = N/A)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resarray[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a data frame so that we can aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnnames=['dirpath', 'inout_id','emailid' ,'topicid', 'prob']\n",
    "\n",
    "df_recommend = pd.DataFrame(resarray[1:,:], columns=columnnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1951525, 5)\n",
      "(1951526, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_recommend.shape\n",
    "print resarray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast probabilities back to float. We needed them as chars to unpack as array doesn't accept mixed data types and we have a dirpath there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_recommend['prob']=df_recommend['prob'].apply(lambda x : float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirpath</th>\n",
       "      <th>inout_id</th>\n",
       "      <th>emailid</th>\n",
       "      <th>topicid</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dirpath inout_id emailid topicid   prob\n",
       "0  hain-m        0       0       0  0.025\n",
       "1  hain-m        0       0       1  0.025\n",
       "2  hain-m        0       0       2  0.025\n",
       "3  hain-m        0       0       3  0.025\n",
       "4  hain-m        0       0       4  0.025\n",
       "5  hain-m        0       0       5  0.025\n",
       "6  hain-m        0       0       6  0.025\n",
       "7  hain-m        0       0       7  0.025\n",
       "8  hain-m        0       0       8  0.025\n",
       "9  hain-m        0       0       9  0.025"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check precision since we are going to sum\n",
    "\n",
    "### OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32674993661000001"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend.iloc[2345,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add counter columns and aggregate to get IN_sum and OUT_sum as well as number of emails per folder (plus inout_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend['count_emails']= 1\n",
    "df_grouped =df_recommend.groupby(['dirpath','inout_id', 'topicid'], as_index=False)[['prob', 'count_emails']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5796, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirpath</th>\n",
       "      <th>inout_id</th>\n",
       "      <th>topicid</th>\n",
       "      <th>prob</th>\n",
       "      <th>count_emails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.038677</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.018270</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>70.678547</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>212.328779</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dirpath inout_id topicid        prob  count_emails\n",
       "0  allen-p        0       0  120.038677           635\n",
       "1  allen-p        0       1   64.018270           462\n",
       "2  allen-p        0      10   70.678547           427\n",
       "3  allen-p        0      11  212.328779           832"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_grouped.shape\n",
    "df_grouped[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK! We have about 150 folders here, 20 topics, and in and out box, which amounts to 150*20*2= 6000. However not all folders may have a score for all topics with values above threshold set in the gensim  software to return by a model object---as the gensim code author explained in a blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split frame to in and out box parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_grouped_in=df_grouped[df_grouped['inout_id']=='0']\n",
    "\n",
    "df_grouped_out=df_grouped[df_grouped['inout_id']=='1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Makes sense, we certainly have one value per outbox topic combination and a few less for the outbox part as we miss few out boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2796, 5)\n",
      "(3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_grouped_out.shape\n",
    "print df_grouped_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_out.rename(columns={'dirpath': 'mentor', 'prob': 'OUT_sum'}, inplace=True)\n",
    "df_grouped_in.rename(columns={'dirpath': 'mentee', 'prob': 'IN_sum'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_joined = df_grouped_out.merge(right=df_grouped_in, how='inner', left_on=['mentor', 'topicid'],\\\n",
    "                                 right_on=['mentee', 'topicid'], suffixes=('_mentor', '_mentee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentor</th>\n",
       "      <th>inout_id_mentor</th>\n",
       "      <th>topicid</th>\n",
       "      <th>OUT_sum</th>\n",
       "      <th>count_emails_mentor</th>\n",
       "      <th>mentee</th>\n",
       "      <th>inout_id_mentee</th>\n",
       "      <th>IN_sum</th>\n",
       "      <th>count_emails_mentee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.295934</td>\n",
       "      <td>65</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>120.038677</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.660352</td>\n",
       "      <td>24</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>64.018270</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.527964</td>\n",
       "      <td>14</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>70.678547</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>24.096311</td>\n",
       "      <td>82</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>212.328779</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mentor inout_id_mentor topicid    OUT_sum  count_emails_mentor   mentee  \\\n",
       "0  allen-p               1       0  20.295934                   65  allen-p   \n",
       "1  allen-p               1       1   4.660352                   24  allen-p   \n",
       "2  allen-p               1      10   0.527964                   14  allen-p   \n",
       "3  allen-p               1      11  24.096311                   82  allen-p   \n",
       "\n",
       "  inout_id_mentee      IN_sum  count_emails_mentee  \n",
       "0               0  120.038677                  635  \n",
       "1               0   64.018270                  462  \n",
       "2               0   70.678547                  427  \n",
       "3               0  212.328779                  832  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_joined['INsum_OUTsum']=df_joined[['OUT_sum', 'IN_sum']].apply(lambda x: x[0]/x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ratio (IN_sum+beta) /(OUT_sum+beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta=0.1\n",
    "def in_over_out(x):\n",
    "    return (x['IN_sum']+beta)/(x['OUT_sum']+beta)\n",
    "df_joined['INsum_OUTsum']=df_joined.apply(in_over_out, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_joined_save=df_joined[['mentor', 'topicid', 'OUT_sum', 'IN_sum', 'INsum_OUTsum']]\n",
    "filedfjoined= file('/notebooks/LDA models and data/Data Frames and lists/expertise_preferance_scores.pkl', 'wb')\n",
    "cPickle.dump(obj=df_joined_save, file=filedfjoined, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentor</th>\n",
       "      <th>inout_id_mentor</th>\n",
       "      <th>topicid</th>\n",
       "      <th>OUT_sum</th>\n",
       "      <th>count_emails_mentor</th>\n",
       "      <th>mentee</th>\n",
       "      <th>inout_id_mentee</th>\n",
       "      <th>IN_sum</th>\n",
       "      <th>count_emails_mentee</th>\n",
       "      <th>INsum_OUTsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.295934</td>\n",
       "      <td>65</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>120.038677</td>\n",
       "      <td>635</td>\n",
       "      <td>5.890325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.660352</td>\n",
       "      <td>24</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>64.018270</td>\n",
       "      <td>462</td>\n",
       "      <td>13.469228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.527964</td>\n",
       "      <td>14</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>70.678547</td>\n",
       "      <td>427</td>\n",
       "      <td>112.711174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>24.096311</td>\n",
       "      <td>82</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>0</td>\n",
       "      <td>212.328779</td>\n",
       "      <td>832</td>\n",
       "      <td>8.779387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mentor inout_id_mentor topicid    OUT_sum  count_emails_mentor   mentee  \\\n",
       "0  allen-p               1       0  20.295934                   65  allen-p   \n",
       "1  allen-p               1       1   4.660352                   24  allen-p   \n",
       "2  allen-p               1      10   0.527964                   14  allen-p   \n",
       "3  allen-p               1      11  24.096311                   82  allen-p   \n",
       "\n",
       "  inout_id_mentee      IN_sum  count_emails_mentee  INsum_OUTsum  \n",
       "0               0  120.038677                  635      5.890325  \n",
       "1               0   64.018270                  462     13.469228  \n",
       "2               0   70.678547                  427    112.711174  \n",
       "3               0  212.328779                  832      8.779387  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mentors=df_joined[['mentor', 'topicid', 'OUT_sum']]\n",
    "df_mentees=df_joined[['mentee', 'topicid', 'INsum_OUTsum']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As already mentioned the structure of data is such that there are folder topic combinations with no emails that ever had a topic probability above the gensim threshold for returning. In such cases there is obviously no basics for match on that topic (if either mentor or mentee has no sum variable. \n",
    "\n",
    "### This remark actually applies already when defining IN_sum/OUT_sum. One might argue that such case should be handled with more care, however if one receives emails on a topic and never sends any then it s a valid argument  that this person actually has no interest in this topic. This should be confirmed by the stakeholders in a real project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cartesian=df_mentors.merge(right=df_mentees, how='inner', left_on='topicid', right_on='topicid' ,\\\n",
    "                              suffixes=('_mentor', '_mentee'))\n",
    "\n",
    "\n",
    "def mult_cols(x):\n",
    "    return x['OUT_sum']*x['INsum_OUTsum']\n",
    "\n",
    "df_cartesian['topic_match_score']=df_cartesian.apply(mult_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cartesian_agg =df_cartesian.groupby(['mentor', 'mentee'], as_index=False)['topic_match_score'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first result of the final part if our assignment is now obtained.\n",
    "\n",
    "# The table with top 3 recommendations for each folder (as mentor) is produced in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mentor</th>\n",
       "      <th>mentee</th>\n",
       "      <th>topic_match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>8.142937e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>4.318518e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>ybarbo-p</td>\n",
       "      <td>4.305624e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>6.478381e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>lewis-a</td>\n",
       "      <td>4.806095e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>196</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>3.969606e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>347</td>\n",
       "      <td>arora-h</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>3.150637e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>338</td>\n",
       "      <td>arora-h</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>1.082759e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>423</td>\n",
       "      <td>arora-h</td>\n",
       "      <td>ybarbo-p</td>\n",
       "      <td>1.068032e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>489</td>\n",
       "      <td>badeer-r</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>1.016079e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>480</td>\n",
       "      <td>badeer-r</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>2.848544e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>488</td>\n",
       "      <td>badeer-r</td>\n",
       "      <td>lewis-a</td>\n",
       "      <td>2.406828e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>707</td>\n",
       "      <td>bailey-s</td>\n",
       "      <td>ybarbo-p</td>\n",
       "      <td>4.087364e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>631</td>\n",
       "      <td>bailey-s</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>3.104088e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600</td>\n",
       "      <td>bailey-s</td>\n",
       "      <td>gay-r</td>\n",
       "      <td>2.038263e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>773</td>\n",
       "      <td>bass-e</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>1.013579e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>772</td>\n",
       "      <td>bass-e</td>\n",
       "      <td>lewis-a</td>\n",
       "      <td>8.008436e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>736</td>\n",
       "      <td>bass-e</td>\n",
       "      <td>ermis-f</td>\n",
       "      <td>6.420157e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>915</td>\n",
       "      <td>baughman-d</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>7.894178e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>914</td>\n",
       "      <td>baughman-d</td>\n",
       "      <td>lewis-a</td>\n",
       "      <td>3.358747e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>891</td>\n",
       "      <td>baughman-d</td>\n",
       "      <td>haedicke-m</td>\n",
       "      <td>2.353958e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1133</td>\n",
       "      <td>beck-s</td>\n",
       "      <td>ybarbo-p</td>\n",
       "      <td>6.132806e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1057</td>\n",
       "      <td>beck-s</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>5.466215e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1020</td>\n",
       "      <td>beck-s</td>\n",
       "      <td>ermis-f</td>\n",
       "      <td>4.990528e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1162</td>\n",
       "      <td>benson-r</td>\n",
       "      <td>ermis-f</td>\n",
       "      <td>5.573079e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1190</td>\n",
       "      <td>benson-r</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>4.359543e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1199</td>\n",
       "      <td>benson-r</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>3.338128e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1341</td>\n",
       "      <td>blair-l</td>\n",
       "      <td>linder-e</td>\n",
       "      <td>3.532055e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1417</td>\n",
       "      <td>blair-l</td>\n",
       "      <td>ybarbo-p</td>\n",
       "      <td>1.921301e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1332</td>\n",
       "      <td>blair-l</td>\n",
       "      <td>keavey-p</td>\n",
       "      <td>1.561273e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      mentor      mentee  topic_match_score\n",
       "0      63     allen-p    linder-e       8.142937e+04\n",
       "1      54     allen-p    keavey-p       4.318518e+04\n",
       "2     139     allen-p    ybarbo-p       4.305624e+04\n",
       "3     205    arnold-j    linder-e       6.478381e+05\n",
       "4     204    arnold-j     lewis-a       4.806095e+05\n",
       "5     196    arnold-j    keavey-p       3.969606e+05\n",
       "6     347     arora-h    linder-e       3.150637e+04\n",
       "7     338     arora-h    keavey-p       1.082759e+04\n",
       "8     423     arora-h    ybarbo-p       1.068032e+04\n",
       "9     489    badeer-r    linder-e       1.016079e+05\n",
       "10    480    badeer-r    keavey-p       2.848544e+04\n",
       "11    488    badeer-r     lewis-a       2.406828e+04\n",
       "12    707    bailey-s    ybarbo-p       4.087364e+04\n",
       "13    631    bailey-s    linder-e       3.104088e+04\n",
       "14    600    bailey-s       gay-r       2.038263e+04\n",
       "15    773      bass-e    linder-e       1.013579e+06\n",
       "16    772      bass-e     lewis-a       8.008436e+05\n",
       "17    736      bass-e     ermis-f       6.420157e+05\n",
       "18    915  baughman-d    linder-e       7.894178e+04\n",
       "19    914  baughman-d     lewis-a       3.358747e+04\n",
       "20    891  baughman-d  haedicke-m       2.353958e+04\n",
       "21   1133      beck-s    ybarbo-p       6.132806e+05\n",
       "22   1057      beck-s    linder-e       5.466215e+05\n",
       "23   1020      beck-s     ermis-f       4.990528e+05\n",
       "24   1162    benson-r     ermis-f       5.573079e+03\n",
       "25   1190    benson-r    keavey-p       4.359543e+03\n",
       "26   1199    benson-r    linder-e       3.338128e+03\n",
       "27   1341     blair-l    linder-e       3.532055e+05\n",
       "28   1417     blair-l    ybarbo-p       1.921301e+05\n",
       "29   1332     blair-l    keavey-p       1.561273e+05"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommendation_engine=df_cartesian_agg.groupby('mentor').head(3).reset_index(drop=True)\n",
    "df_recommendation_engine[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the required total score is (the higher the better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88137833.5072\n"
     ]
    }
   ],
   "source": [
    "recommendation_score =df_recommendation_engine.topic_match_score.sum()\n",
    "print recommendation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the remainder we collect all required statistics for our 3 valuation methods\n",
    "\n",
    "# As simple as it may sound to speak out, writing code for such schema requires some lines\n",
    "\n",
    "### The following 7 cells do the preparatory work, that only needs to be done once. The part that needs be repeated per random sample of folders for each email is partly repetition of what we did to compute recommendation_score, and is all put in a loop in cell 8 from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1=df_recommend[['dirpath','inout_id', 'emailid']].drop_duplicates()\n",
    "df_temp1['count_emails']=1\n",
    "# determine p for np.random_choice call\n",
    "df_p4rc = df_temp1.groupby(['dirpath','inout_id'], as_index=False)['count_emails'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 3)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "df_p4rc_in=df_p4rc[df_p4rc['inout_id']=='0']\n",
    "df_p4rc_out=df_p4rc[df_p4rc['inout_id']=='1']\n",
    "print df_p4rc_out.shape\n",
    "print df_p4rc_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for sampling with replacement\n",
    "# inbox\n",
    "#\n",
    "# prepare\n",
    "email_count_in=df_p4rc_in.count_emails.sum()\n",
    "p_in=df_p4rc_in.count_emails/df_p4rc_in.count_emails.sum()\n",
    "nr_in_folders=df_p4rc_in.shape[0]\n",
    "\n",
    "# sample from inbox id' s with replacement with same distribution p_in\n",
    "rc_in =np.random.choice(a=nr_in_folders, size=email_count_in , replace=True, p=p_in)\n",
    "\n",
    "\n",
    "# outbox\n",
    "#\n",
    "# prepare\n",
    "email_count_out=df_p4rc_out.count_emails.sum()\n",
    "p_out=df_p4rc_out.count_emails/df_p4rc_out.count_emails.sum()\n",
    "nr_out_folders=df_p4rc_out.shape[0]\n",
    "\n",
    "# # sample from outbox id's with replacement with same distribution p_out\n",
    "# rc_out =np.random.choice(a=nr_out_folders, size=email_count_out , replace=True, p=p_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dirpath_id needed\n",
    "# prep for in folder\n",
    "df_tmpin = df_recommend[df_recommend['inout_id']=='0'].iloc[:,0:2].drop_duplicates()\n",
    "tmpin = np.array(range(0,nr_in_folders))\n",
    "df_tmpin['dirpath_id']=tmpin\n",
    "\n",
    "# prep for out folder\n",
    "df_tmpout = df_recommend[df_recommend['inout_id']=='1'].iloc[:,0:2].drop_duplicates()\n",
    "tmpout = np.array(range(0,nr_out_folders))\n",
    "df_tmpout['dirpath_id']=tmpout\n",
    "\n",
    "# concatenate so we have an id per folder name and inout_id value\n",
    "df_tmp = pd.concat([df_tmpin, df_tmpout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirpath</th>\n",
       "      <th>inout_id</th>\n",
       "      <th>emailid</th>\n",
       "      <th>topicid</th>\n",
       "      <th>prob</th>\n",
       "      <th>count_emails</th>\n",
       "      <th>dirpath_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hain-m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dirpath inout_id emailid topicid   prob  count_emails  dirpath_id\n",
       "0  hain-m        0       0       0  0.025             1           0\n",
       "1  hain-m        0       0       1  0.025             1           0\n",
       "2  hain-m        0       0       2  0.025             1           0\n",
       "3  hain-m        0       0       3  0.025             1           0\n",
       "4  hain-m        0       0       4  0.025             1           0"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add this column to full frame df_recommend where one rwo stands for dirpath, inout_id, topic and corresponding \n",
    "# sum of probbailities\n",
    "df_recommend1 = df_recommend.merge(right=df_tmp, how='left', left_on=['dirpath', 'inout_id'],\\\n",
    "                                 right_on=['dirpath', 'inout_id'])\n",
    "df_recommend1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x):\n",
    "    return int(x['emailid'])\n",
    "df_recommend1['emailid']=df_recommend1.apply(to_int, axis=1)\n",
    "# df_recommend1[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149379, 4)\n"
     ]
    }
   ],
   "source": [
    "# rc_in[df_recommend1.dirpath_id[0]]\n",
    "# df_recommend1.dirpath_id[0]\n",
    "\n",
    "df_tmpin2 = df_recommend1[df_recommend1['inout_id']=='0'][['dirpath','inout_id', 'emailid', 'dirpath_id']].drop_duplicates()\n",
    "df_tmpout2 = df_recommend1[df_recommend1['inout_id']=='1'][['dirpath','inout_id', 'emailid', 'dirpath_id']].drop_duplicates()\n",
    "print df_tmpout2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here everything needs to be recomputed per random reassignment of directories to emails.\n",
    "\n",
    "### We nonetheless provide code with comments but leave then commented (in case a reader wishes to execute the pieces of code that happen in that loop), yet for readability we comment them out of executable code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_dir_in():\n",
    "#     return np.random.choice(a=nr_in_folders, size=1 , replace=True, p=p_in)\n",
    "\n",
    "# # =np.random.choice(a=nr_in_folders, size=1 , replace=True, p=p_in)\n",
    "# def random_dir_out():\n",
    "#     return np.random.choice(a=nr_out_folders, size=1 , replace=True, p=p_out) \n",
    "\n",
    "# df_tmpin2['random_dirpath_id']=df_tmpin2['emailid'].apply(lambda x: random_dir_in()[0])\n",
    "# df_tmpout2['random_dirpath_id']=df_tmpout2['emailid'].apply(lambda x: random_dir_out()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame df_recommend2 has now randomly resigned folder id's and we can repeat the same thing we did above, in a loop and each time compute total score. Instead of aggregating on ' dirpath' we need to aggregate on 'random_dirpath_id' here metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_recommend1_in = df_recommend1[df_recommend1['inout_id']=='0']\n",
    "df_recommend1_in= df_recommend1_in.merge(right=df_tmpin2,  how='inner',  left_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'],\\\n",
    "                                 right_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'])\n",
    "\n",
    "\n",
    "\n",
    "df_recommend1_out = df_recommend1[df_recommend1['inout_id']=='1']\n",
    "df_recommend1_out= df_recommend1_out.merge(right=df_tmpout2,  how='inner',  left_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'],\\\n",
    "                                 right_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'])\n",
    "\n",
    "df_recommend2=pd.concat([df_recommend1_out, df_recommend1_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_recommend2=df_tmp = pd.concat([df_recommend1_out, df_recommend1_in]).ipynb_checkpoints/\n",
    "df_recommend2=df_recommend2[['inout_id', 'emailid', 'topicid', 'prob', 'random_dirpath_id']].\\\n",
    "rename(columns={'random_dirpath_id': 'dirpath'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions:\n",
    "\n",
    "#### 1) for IN_sum/OUT_sum computation\n",
    "\n",
    "#### 2) Multiply two columns\n",
    "\n",
    "#### 3) sample directory id's at random with distributiin as generated by in and out folders (probability of guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta=0.1\n",
    "def in_over_out(x):\n",
    "    return (x['IN_sum']+beta)/(x['OUT_sum']+beta)\n",
    "\n",
    "#####################################\n",
    "\n",
    "def mult_cols(x):\n",
    "    return x['OUT_sum']*x['INsum_OUTsum']\n",
    "####################################\n",
    "\n",
    "def random_dir_in():\n",
    "    return np.random.choice(a=nr_in_folders, size=1 , replace=True, p=p_in)\n",
    "\n",
    "def random_dir_out():\n",
    "    return np.random.choice(a=nr_out_folders, size=1 , replace=True, p=p_out) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_recommend1_in = df_recommend1[df_recommend1['inout_id']=='0']\n",
    "df_recommend1_in= df_recommend1_in.merge(right=df_tmpin2,  how='inner',  left_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'],\\\n",
    "                                 right_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'])\n",
    "\n",
    "\n",
    "\n",
    "df_recommend1_out = df_recommend1[df_recommend1['inout_id']=='1']\n",
    "df_recommend1_out= df_recommend1_out.merge(right=df_tmpout2,  how='inner',  left_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'],\\\n",
    "                                 right_on=['dirpath', 'inout_id', 'emailid', 'dirpath_id'])\n",
    "\n",
    "df_recommend2=df_tmp = pd.concat([df_recommend1_out, df_recommend1_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inout_id</th>\n",
       "      <th>emailid</th>\n",
       "      <th>topicid</th>\n",
       "      <th>prob</th>\n",
       "      <th>dirpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.362389</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.195750</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.373782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  inout_id  emailid topicid      prob  dirpath\n",
       "0        1        8       0  0.362389        7\n",
       "1        1        8      10  0.055380        7\n",
       "2        1        8      11  0.195750        7\n",
       "3        1        8      17  0.373782        7\n",
       "4        1       14      13  0.105881       70"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples=100\n",
    "matching_scores = np.zeros(shape=(number_of_samples,), dtype=float)\n",
    "# k=0\n",
    "for j in range(0, number_of_samples):\n",
    "#     k=k+1\n",
    "    df_tmpin2['random_dirpath_id']=df_tmpin2['emailid'].apply(lambda x: random_dir_in()[0])\n",
    "    df_tmpout2['random_dirpath_id']=df_tmpout2['emailid'].apply(lambda x: random_dir_out()[0])\n",
    "\n",
    "    df_grouped2 =df_recommend2.groupby(['dirpath','inout_id', 'topicid'], as_index=False)['prob'].sum()\n",
    "\n",
    "    df_grouped_in2=df_grouped2[df_grouped2['inout_id']=='0']\n",
    "    df_grouped_out2=df_grouped2[df_grouped2['inout_id']=='1']\n",
    "\n",
    "    df_grouped_out2.rename(columns={'dirpath': 'mentor', 'prob': 'OUT_sum'}, inplace=True)\n",
    "    df_grouped_in2.rename(columns={'dirpath': 'mentee', 'prob': 'IN_sum'}, inplace=True)\n",
    "\n",
    "    df_joined2 = df_grouped_out2.merge(right=df_grouped_in2, how='inner', left_on=['mentor', 'topicid'],\\\n",
    "                                     right_on=['mentee', 'topicid'], suffixes=('_mentor', '_mentee'))\n",
    "\n",
    "\n",
    "    df_joined2['INsum_OUTsum']=df_joined.apply(in_over_out, axis=1)\n",
    "\n",
    "    df_mentors2=df_joined2[['mentor', 'topicid', 'OUT_sum']]\n",
    "    df_mentees2=df_joined2[['mentee', 'topicid', 'INsum_OUTsum']]\n",
    "\n",
    "    df_cartesian2=df_mentors.merge(right=df_mentees2, how='inner', left_on='topicid', right_on='topicid' ,\\\n",
    "                                  suffixes=('_mentor', '_mentee'))\n",
    "\n",
    "\n",
    "    df_cartesian2['topic_match_score']=df_cartesian2.apply(mult_cols, axis=1)\n",
    "\n",
    "    df_cartesian2=df_mentors2.merge(right=df_mentees2, how='inner', left_on='topicid', right_on='topicid' ,\\\n",
    "                                  suffixes=('_mentor', '_mentee'))\n",
    "\n",
    "\n",
    "    df_cartesian2['topic_match_score']=df_cartesian2.apply(mult_cols, axis=1)\n",
    "\n",
    "    df_cartesian_agg2 =df_cartesian2.groupby(['mentor', 'mentee'], as_index=False)['topic_match_score'].sum()\n",
    "\n",
    "    df_recommendation_engine2=df_cartesian_agg2.groupby('mentor').head(3).reset_index(drop=True)\n",
    "    recommendation_score2 =df_recommendation_engine2.topic_match_score.sum()\n",
    "    matching_scores[j]=recommendation_score2\n",
    "#     print recommendation_score2\n",
    "#     print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88137833.5072\n",
      "2232129.58661\n"
     ]
    }
   ],
   "source": [
    "print recommendation_score \n",
    "print recommendation_score2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
