{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script content\n",
    "\n",
    "### This script loads all emails from all directories into a list and then data frame and determines which email address belongs to the folder owner-based on exact string match with first and second word in X-from of each email. This also allows us to dermine which emails are inbox and which out. Directories structure or names are not sufficient for a safe procedure.\n",
    "\n",
    "### Further, we strip emails with forwarded emails in their body from all non-body parts in all forwards in the therad.\n",
    "\n",
    "### Finally we strip environmental and provacy warnings at the bottom of emails.\n",
    "\n",
    "### We save result dat aframe on the disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use email package to extract (half) structured data from emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from email.parser import Parser\n",
    "rootdir = \"/notebooks/LDA models and data/Data Frames and lists/Enron3/maildir/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first write a helper function to parse email and produce a list with needed fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_analyse(inputfile,  email_list):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    email = Parser().parsestr(data)\n",
    "    X_from = email['X-from']\n",
    "    email_from= email['From']\n",
    "    email_date= email['date']\n",
    "    email_body = email.get_payload()\n",
    "    email_list.append([os.path.join(directory, filename), email_from, X_from, email_date, email_body])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then extract all emails from all folders to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_list = []\n",
    "\n",
    "for directory, subdirectory, filenames in  os.walk(rootdir):\n",
    "    for filename in filenames:\n",
    "        email_analyse(os.path.join(directory, filename), email_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a data frame from emails list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_emails = pd.DataFrame(email_list, columns=['dirpath' ,'from', 'Xfrom', 'date', 'body'])\n",
    "df_emails=df_emails.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract folder name that contains surname and first letter of name of executive\n",
    "\n",
    "#### We make empty string out of X-from fileds that are NonType for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails['dirpath']=df_emails['dirpath'].apply(lambda x: x.split('/')[])\n",
    "\n",
    "df_emails['Xfrom'] =  df_emails['Xfrom'].apply(lambda x: x if type(x) == str else '')\n",
    "# print df_emails[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper function to extract and helper functions to remove undesired characters in data frame columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def f1(x):\n",
    "    lst = x.replace('\"', '').strip().upper().split(' ')\n",
    "    result = ''\n",
    "    if len(lst) > 1:\n",
    "        result =  lst[1]\n",
    "    return result \n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    str2 = x.replace(',', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str2) > 1:\n",
    "        result =  str2\n",
    "    return result \n",
    "\n",
    "def f3(x):\n",
    "    str3 = x.replace(';', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str3) > 1:\n",
    "        result =  str3\n",
    "    return result\n",
    "\n",
    "def f4(x):\n",
    "    str4 = x.replace('\\\\', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str4) > 1:\n",
    "        result =  str4\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and first and second word (mostly name or sometimes surname from X-from and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First word\n",
    "df_emails['Xfrom0']=df_emails['Xfrom'].apply(lambda x: x.replace('\"', '').strip().upper().split(' ')[0])\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f3(x))\n",
    "\n",
    "# Second word where there is one\n",
    "df_emails['Xfrom1']=df_emails['Xfrom'].apply(lambda x: f1(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f3(x))\n",
    "\n",
    "# extact actual surname\n",
    "df_emails['dirpath_surname']=df_emails['dirpath'].apply(lambda x: x.strip().upper().split('-')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computre Levenshtein distance between direcory surname and second and first word in X-from as these seem to appear on both orders\n",
    "### On my machine with 256GB RAM and 24 cores processor it takes a few minutes to complete\n",
    "\n",
    "#### Afterall it turned out that we could have directly done a an exact string match, but that we did not knwo in advance. As it doesnt take to long to process we keep this part as it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance as ed\n",
    "\n",
    "df_emails['dist1'] = df_emails[['Xfrom1', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom1'], x['dirpath_surname']), axis=1)\n",
    "df_emails['dist0'] = df_emails[['Xfrom0', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom0'], x['dirpath_surname']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute minimal Levenshtein distance at directory surname level\n",
    "df_emails_grouped = df_emails.groupby(['dirpath_surname']).agg({'dist1':'min', 'dist0':'min'}).reset_index().\\\n",
    "rename(columns={'dist1':'dist1_min', 'dist0':'dist0_min'})\n",
    "\n",
    "df_emails = pd.merge(df_emails, df_emails_grouped, how='left', on=['dirpath_surname'])\n",
    "\n",
    "df_emails_mindist = df_emails[(df_emails['dist1_min'] == 0) | (df_emails['dist0_min'] == 0)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slect emails with minimal distance.\n",
    "### Iturns out that not all folders actually contain a from email with a matching name (out of 135 we matched 127) and we choose for ur recomendation engine mentors and mentees only out of those executives who's name matches completely in the above way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK\n",
    "print df_emails_mindist['dirpath_surname'].drop_duplicates().shape\n",
    "print df_emails['dirpath_surname'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOTHER CHECK\n",
    "\n",
    "#### check how many mails are dropped this way; 2.5% emails dropped OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_emails_mindist.shape\n",
    "print df_emails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to (attempt to) keep only the party of email body written by the sender in out email, which we later on need for experise and preferances determination we will chop all email bodies from first appearance of any of the typical strings as in functions below. Our method is far from exhaustive from this from aspect of text prpcessing but due to lack of time we will proceed with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def h1(x):\n",
    "    return x.split('********************************')[0]\n",
    "\n",
    "def h2(x):\n",
    "    return x.split('-----Original Message-----')[0]\n",
    "\n",
    "def h3(x):\n",
    "    return x.split('__________________________')[0]\n",
    "\n",
    "def h4(x):\n",
    "    return x.split('---Forwarded by')[0]\n",
    "\n",
    "def h5(x):\n",
    "    return x.split('---Forwarded By')[0]\n",
    "\n",
    "def h6(x):\n",
    "    return x.split('--- Forwarded by')[0]\n",
    "\n",
    "def h7(x):\n",
    "    return x.split('--- Forwarded By')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign copy of df_emails to prcess further for preferances/expertise detrmination and chop email bodies for preferances/experise determination. Notice that we keep these parts for the topics modeling part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails0=df_emails\n",
    "\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h1(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h2(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h3(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h4(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h5(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h6(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h7(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emails can have forwarded emails below or environment cautions/pricay warnings at the bottom of them. Since this can be the case with many emails we need to strip these pieces of text to avoid noise in our topic modeling. We start with defining regex objects that we need for this processing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "email_pat = re.compile(\".+@.+\")\n",
    "to_pat = re.compile(\"To:.+\\n\")\n",
    "cc_pat = re.compile(\"cc:.+\\n\")\n",
    "subject_pat = re.compile(\"Subject:.+\\n\")\n",
    "from_pat = re.compile(\"From:.+\\n\")\n",
    "sent_pat = re.compile(\"Sent:.+\\n\")\n",
    "received_pat = re.compile(\"Received:.+\\n\")\n",
    "ctype_pat = re.compile(\"Content-Type:.+\\n\")\n",
    "reply_pat = re.compile(\"Reply- Organization:.+\\n\")\n",
    "date_pat = re.compile(\"Date:.+\\n\")\n",
    "xmail_pat = re.compile(\"X-Mailer:.+\\n\")\n",
    "mimver_pat = re.compile(\"MIME-Version:.+\\n\")\n",
    "dash_pat = re.compile(\"--+.+--+\", re.DOTALL)\n",
    "star_pat = re.compile('\\*\\*+.+\\*\\*+', re.DOTALL)\n",
    "uscore_pat = re.compile(\" __+.+__+\", re.DOTALL)\n",
    "equals_pat = re.compile(\"==+.+==+\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we define a function that takes the body of am email (possibly containing forward email threads and/or environment warnings/provacy cautions) and returns sole email text (also from emails of a full forward thear where applicable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_forward_email(email):    \n",
    "    etype=''\n",
    "    if '.nsf' in email:\n",
    "        etype = \".nsf\"\n",
    "    elif '.pst' in email:\n",
    "        etype = '.pst'\n",
    "    email_new = email[email.find(etype)+4:]\n",
    "    email_new = to_pat.sub('', email_new)\n",
    "    email_new = cc_pat.sub('', email_new)\n",
    "    email_new = subject_pat.sub('', email_new)\n",
    "    email_new = from_pat.sub('', email_new)\n",
    "    email_new = sent_pat.sub('', email_new)\n",
    "    email_new = received_pat.sub('', email_new)\n",
    "    email_new = email_pat.sub('', email_new)\n",
    "    email_new = ctype_pat.sub('', email_new)\n",
    "    email_new = reply_pat.sub('', email_new)\n",
    "    email_new = date_pat.sub('', email_new)\n",
    "    email_new = xmail_pat.sub('', email_new)\n",
    "    email_new = mimver_pat.sub('', email_new)\n",
    "    email_new = dash_pat.sub('', email_new)\n",
    "    email_new = star_pat.sub('', email_new)\n",
    "    email_new = uscore_pat.sub('', email_new)\n",
    "    email_new = equals_pat.sub('', email_new)\n",
    "    return email_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process email body column in the full dat aframe containing all emails. These will be used for topic modeling and it seems perfectly sound to consider full thread as one document with common topic(s)\n",
    "\n",
    "### The reduced table df_emails_mindist need additional step. Namely there we need to determine preferances and for that we need to be more precise about what each executive writes and what he/she reads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails['body']=df_emails['body'].apply(lambda x: clean_forward_email(x))\n",
    "\n",
    "# just to be sure we do the same to df_emails0\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: clean_forward_email(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in vs out box id column to both frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inoutfunct(x):\n",
    "    result=0\n",
    "    if (x['dist1']==0 or x['dist0']==0):\n",
    "        result= 1\n",
    "    return result\n",
    "df_emails0['inout_id']=df_emails.apply(inoutfunct, axis=1)\n",
    "df_emails['inout_id']=df_emails.apply(inoutfunct, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_emails.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails.pkl')\n",
    "df_email0s.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails0.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
