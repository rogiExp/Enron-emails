{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script content\n",
    "### This script loads all emails from all directories into a list and then a data frame and determines which email address belongs to the folder owner.\n",
    "### We do that based on exact string match with first and second word in X-from of each email. This also allows us to determine which emails are inbox and which out. Directory structures or names are not sufficient for a safe procedure.\n",
    "### Further, we strip emails that contain forwarded emails in their body from these parts for a version of processing to be used for recommendation engine.\n",
    "### Finally we strip environmental and privacy warnings at the bottom of emails.\n",
    "### At last we save result data frame on the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use email package to extract (half) structured data from emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from email.parser import Parser\n",
    "rootdir = \"/notebooks/LDA models and data/Data Frames and lists/Enron3/maildir/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first write a helper function to parse email and produce a list with needed fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_analyse(inputfile,  email_list):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    email = Parser().parsestr(data)\n",
    "    X_from = email['X-from']\n",
    "    email_from= email['From']\n",
    "    email_date= email['date']\n",
    "    email_body = email.get_payload()\n",
    "    email_list.append([os.path.join(directory, filename), email_from, X_from, email_date, email_body])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then extract all emails from all folders to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_list = []\n",
    "\n",
    "for directory, subdirectory, filenames in  os.walk(rootdir):\n",
    "    for filename in filenames:\n",
    "        email_analyse(os.path.join(directory, filename), email_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a data frame from emails list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_emails = pd.DataFrame(email_list, columns=['dirpath' ,'from', 'Xfrom', 'date', 'body'])\n",
    "df_emails=df_emails.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract folder name that contains surname and first letter of name of executive\n",
    "\n",
    "#### We make empty string out of X-from fields that are NonType for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails['dirpath']=df_emails['dirpath'].apply(lambda x: x.split('/')[])\n",
    "\n",
    "df_emails['Xfrom'] =  df_emails['Xfrom'].apply(lambda x: x if type(x) == str else '')\n",
    "# print df_emails[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper function to extract and helper functions to remove undesired characters in data frame columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def f1(x):\n",
    "    lst = x.replace('\"', '').strip().upper().split(' ')\n",
    "    result = ''\n",
    "    if len(lst) > 1:\n",
    "        result =  lst[1]\n",
    "    return result \n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    str2 = x.replace(',', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str2) > 1:\n",
    "        result =  str2\n",
    "    return result \n",
    "\n",
    "def f3(x):\n",
    "    str3 = x.replace(';', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str3) > 1:\n",
    "        result =  str3\n",
    "    return result\n",
    "\n",
    "def f4(x):\n",
    "    str4 = x.replace('\\\\', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str4) > 1:\n",
    "        result =  str4\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and first and second word (mostly name or sometimes surname from X-from and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First word\n",
    "df_emails['Xfrom0']=df_emails['Xfrom'].apply(lambda x: x.replace('\"', '').strip().upper().split(' ')[0])\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f3(x))\n",
    "\n",
    "# Second word where there is one\n",
    "df_emails['Xfrom1']=df_emails['Xfrom'].apply(lambda x: f1(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f3(x))\n",
    "\n",
    "# extact actual surname\n",
    "df_emails['dirpath_surname']=df_emails['dirpath'].apply(lambda x: x.strip().upper().split('-')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Levenshtein distance between directory surname and second and first word in X-from as these seem to appear on both orders\n",
    "#### On my machine with 256GB RAM and 24 cores processor it takes a few minutes to complete\n",
    "\n",
    "#### After all it turned out that we could have directly done a an exact string match, but that we did not know in advance. As it doesnâ€™t take too long to process we keep this part as it is\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance as ed\n",
    "\n",
    "df_emails['dist1'] = df_emails[['Xfrom1', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom1'], x['dirpath_surname']), axis=1)\n",
    "df_emails['dist0'] = df_emails[['Xfrom0', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom0'], x['dirpath_surname']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute minimal Levenshtein distance at directory surname level\n",
    "df_emails_grouped = df_emails.groupby(['dirpath_surname']).agg({'dist1':'min', 'dist0':'min'}).reset_index().\\\n",
    "rename(columns={'dist1':'dist1_min', 'dist0':'dist0_min'})\n",
    "\n",
    "df_emails = pd.merge(df_emails, df_emails_grouped, how='left', on=['dirpath_surname'])\n",
    "\n",
    "df_emails_mindist = df_emails[(df_emails['dist1_min'] == 0) | (df_emails['dist0_min'] == 0)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select emails with minimal distance.\n",
    "### It turns out that not all folders actually contain an from email with a matching name (out of 135 we matched 127) and we choose for our recommendation engine mentors and mentees only out of those executives who's name matches completely in a way as described above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK\n",
    "print df_emails_mindist['dirpath_surname'].drop_duplicates().shape\n",
    "print df_emails['dirpath_surname'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOTHER CHECK\n",
    "\n",
    "#### check how many mails are dropped this way; 2.5% emails dropped OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_emails_mindist.shape\n",
    "print df_emails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to keep only the part of email body written by the sender in out email, which we later on need for expertise and preferences determination we will chop all email bodies from first appearance of any of the typical strings as in functions below. \n",
    "\n",
    "### Our method is far from exhaustive from this from aspect of text preprocessing but due to lack of time we will proceed with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def h1(x):\n",
    "    return x.split('********************************')[0]\n",
    "\n",
    "def h2(x):\n",
    "    return x.split('-----Original Message-----')[0]\n",
    "\n",
    "def h3(x):\n",
    "    return x.split('__________________________')[0]\n",
    "\n",
    "def h4(x):\n",
    "    return x.split('---Forwarded by')[0]\n",
    "\n",
    "def h5(x):\n",
    "    return x.split('---Forwarded By')[0]\n",
    "\n",
    "def h6(x):\n",
    "    return x.split('--- Forwarded by')[0]\n",
    "\n",
    "def h7(x):\n",
    "    return x.split('--- Forwarded By')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign copy of df_emails to process further for preferences/expertise determination and chop email bodies in order to determine preferences/expertise. Notice that we keep these parts for the topics modeling part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails0=df_emails\n",
    "\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h1(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h2(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h3(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h4(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h5(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h6(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h7(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emails can have forwarded emails below or environment cautions/privacy warnings at the bottom of them. Since this can be the case with many emails we need to strip these pieces of text to avoid noise in our topic modeling. We start with defining regex objects that we need for this processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "email_pat = re.compile(\".+@.+\")\n",
    "to_pat = re.compile(\"To:.+\\n\")\n",
    "cc_pat = re.compile(\"cc:.+\\n\")\n",
    "subject_pat = re.compile(\"Subject:.+\\n\")\n",
    "from_pat = re.compile(\"From:.+\\n\")\n",
    "sent_pat = re.compile(\"Sent:.+\\n\")\n",
    "received_pat = re.compile(\"Received:.+\\n\")\n",
    "ctype_pat = re.compile(\"Content-Type:.+\\n\")\n",
    "reply_pat = re.compile(\"Reply- Organization:.+\\n\")\n",
    "date_pat = re.compile(\"Date:.+\\n\")\n",
    "xmail_pat = re.compile(\"X-Mailer:.+\\n\")\n",
    "mimver_pat = re.compile(\"MIME-Version:.+\\n\")\n",
    "dash_pat = re.compile(\"--+.+--+\", re.DOTALL)\n",
    "star_pat = re.compile('\\*\\*+.+\\*\\*+', re.DOTALL)\n",
    "uscore_pat = re.compile(\" __+.+__+\", re.DOTALL)\n",
    "equals_pat = re.compile(\"==+.+==+\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we define a function that takes the body of am email (possibly containing forward email threads and/or environment warnings/privacy cautions) and returns sole email text (also from emails of a full forward where applicable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_forward_email(email):    \n",
    "    etype=''\n",
    "    if '.nsf' in email:\n",
    "        etype = \".nsf\"\n",
    "    elif '.pst' in email:\n",
    "        etype = '.pst'\n",
    "    email_new = email[email.find(etype)+4:]\n",
    "    email_new = to_pat.sub('', email_new)\n",
    "    email_new = cc_pat.sub('', email_new)\n",
    "    email_new = subject_pat.sub('', email_new)\n",
    "    email_new = from_pat.sub('', email_new)\n",
    "    email_new = sent_pat.sub('', email_new)\n",
    "    email_new = received_pat.sub('', email_new)\n",
    "    email_new = email_pat.sub('', email_new)\n",
    "    email_new = ctype_pat.sub('', email_new)\n",
    "    email_new = reply_pat.sub('', email_new)\n",
    "    email_new = date_pat.sub('', email_new)\n",
    "    email_new = xmail_pat.sub('', email_new)\n",
    "    email_new = mimver_pat.sub('', email_new)\n",
    "    email_new = dash_pat.sub('', email_new)\n",
    "    email_new = star_pat.sub('', email_new)\n",
    "    email_new = uscore_pat.sub('', email_new)\n",
    "    email_new = equals_pat.sub('', email_new)\n",
    "    return email_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process email body column in the full data frame containing all emails. These will be used for topic modeling and it seems perfectly sound to consider full thread as one document with common topic(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emails['body']=df_emails['body'].apply(lambda x: clean_forward_email(x))\n",
    "\n",
    "# just to be sure we do the same to df_emails0\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: clean_forward_email(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in vs out box id column to both frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inoutfunct(x):\n",
    "    result=0\n",
    "    if (x['dist1']==0 or x['dist0']==0):\n",
    "        result= 1\n",
    "    return result\n",
    "df_emails0['inout_id']=df_emails.apply(inoutfunct, axis=1)\n",
    "df_emails['inout_id']=df_emails.apply(inoutfunct, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_emails.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails.pkl')\n",
    "df_email0s.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails0.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
