{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script loads all emails from all directories into a list and then data frame and determines which email address\n",
    "# belongs to the folder owner-based on exact string match with first and second word in X-from of each email. This\n",
    "# also allows us to dermine which emails are inbox and which out. Directories structure or names are not sufficient for \n",
    "# a safe procedure.\n",
    "\n",
    "# Further, we strip emails with forwarded emails in their body from all non-body parts in all forwards in the therad.\n",
    "# Finally we strip environmental and provacy warnings at the bottom of emails.\n",
    "\n",
    "# We save result dat a frame on the disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# we will use email package to extract (half) structured data from emails\n",
    "from email.parser import Parser\n",
    "rootdir = \"/notebooks/LDA models and data/Data Frames and lists/Enron3/maildir/\"\n",
    "\n",
    "# helper function to parse email and produce a list with needed fields\n",
    "def email_analyse(inputfile,  email_list):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    email = Parser().parsestr(data)\n",
    "    X_from = email['X-from']\n",
    "    email_from= email['From']\n",
    "    email_date= email['date']\n",
    "    email_body = email.get_payload()\n",
    "    email_list.append([os.path.join(directory, filename), email_from, X_from, email_date, email_body])\n",
    "\n",
    "\n",
    "email_list = []\n",
    "\n",
    "for directory, subdirectory, filenames in  os.walk(rootdir):\n",
    "    for filename in filenames:\n",
    "        email_analyse(os.path.join(directory, filename), email_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# make a data frame from emails list\n",
    "df_emails = pd.DataFrame(email_list, columns=['dirpath' ,'from', 'Xfrom', 'date', 'body'])\n",
    "df_emails=df_emails.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract folder name that contains surname and first letter of name of executive\n",
    "df_emails['dirpath']=df_emails['dirpath'].apply(lambda x: x.split('/')[])\n",
    "\n",
    "# make empty string out of X-from fileds that are NonType for processing\n",
    "df_emails['Xfrom'] =  df_emails['Xfrom'].apply(lambda x: x if type(x) == str else '')\n",
    "# print df_emails[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to extract\n",
    "def f1(x):\n",
    "    lst = x.replace('\"', '').strip().upper().split(' ')\n",
    "    result = ''\n",
    "    if len(lst) > 1:\n",
    "        result =  lst[1]\n",
    "    return result \n",
    "\n",
    "# helper functions to remove undesired characters in data frame columns\n",
    "def f2(x):\n",
    "    str2 = x.replace(',', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str2) > 1:\n",
    "        result =  str2\n",
    "    return result \n",
    "\n",
    "def f3(x):\n",
    "    str3 = x.replace(';', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str3) > 1:\n",
    "        result =  str3\n",
    "    return result\n",
    "\n",
    "def f4(x):\n",
    "    str4 = x.replace('\\\\', '').strip().upper()\n",
    "    result = ''\n",
    "    if len(str4) > 1:\n",
    "        result =  str4\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## process Xfrom0\n",
    "# extract first word (mostly name or sometimes surname from X-from and process it\n",
    "df_emails['Xfrom0']=df_emails['Xfrom'].apply(lambda x: x.replace('\"', '').strip().upper().split(' ')[0])\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom0']=df_emails['Xfrom0'].apply(lambda x: f3(x))\n",
    "\n",
    "# extrcat second word form X-from where there is one\n",
    "df_emails['Xfrom1']=df_emails['Xfrom'].apply(lambda x: f1(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f2(x))\n",
    "# remove undesired characters and cast to upper case for string distance evaluation\n",
    "df_emails['Xfrom1']=df_emails['Xfrom1'].apply(lambda x: f3(x))\n",
    "\n",
    "# extact actual surname\n",
    "df_emails['dirpath_surname']=df_emails['dirpath'].apply(lambda x: x.strip().upper().split('-')[0])\n",
    "# print df_emails[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance as ed\n",
    "\n",
    "# computre Levenshtein distance between direcory surname and second and first word in X-from as these seem to appear on both orders\n",
    "# on my machine with 256GB RAM and 24 cores processor (AZURE HPC) it takes a few minutes to complete\n",
    "df_emails['dist1'] = df_emails[['Xfrom1', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom1'], x['dirpath_surname']), axis=1)\n",
    "df_emails['dist0'] = df_emails[['Xfrom0', 'dirpath_surname']].apply(lambda x: ed.eval(x['Xfrom0'], x['dirpath_surname']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute minimal Levenshtein distance at directory surname level\n",
    "df_emails_grouped = df_emails.groupby(['dirpath_surname']).agg({'dist1':'min', 'dist0':'min'}).reset_index().\\\n",
    "rename(columns={'dist1':'dist1_min', 'dist0':'dist0_min'})\n",
    "\n",
    "df_emails = pd.merge(df_emails, df_emails_grouped, how='left', on=['dirpath_surname'])\n",
    "\n",
    "# select emails with minimal distance\n",
    "# it turns out that not all folders actually contain a from email with a matching name (out of 135 we matched 127) and we choose for\n",
    "# our recomendation engine mentors and mentees only out of those executives who's name matches completely in the above way\n",
    "df_emails_mindist = df_emails[(df_emails['dist1_min'] == 0) | (df_emails['dist0_min'] == 0)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK\n",
    "print df_emails_mindist['dirpath_surname'].drop_duplicates().shape\n",
    "print df_emails['dirpath_surname'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANOTHER CHECK\n",
    "# check how many mails are dropped this way; 2.5% emails dropped OK!\n",
    "print df_emails_mindist.shape\n",
    "print df_emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in order to (attempt to) keep only the party of email body written by the sender in out email, which we later on need for experise and preferances\n",
    "# determination we will chop all email bodies from first appearance of any of the typical strings as in functions below. Our method is far from exhaustive r this\n",
    "# from aspect of text prpcessing but due to lack of time we will proceed with it.\n",
    "\n",
    "def h1(x):\n",
    "    return x.split('********************************')[0]\n",
    "\n",
    "def h2(x):\n",
    "    return x.split('-----Original Message-----')[0]\n",
    "\n",
    "def h3(x):\n",
    "    return x.split('__________________________')[0]\n",
    "\n",
    "def h4(x):\n",
    "    return x.split('---Forwarded by')[0]\n",
    "\n",
    "def h5(x):\n",
    "    return x.split('---Forwarded By')[0]\n",
    "\n",
    "def h6(x):\n",
    "    return x.split('--- Forwarded by')[0]\n",
    "\n",
    "def h7(x):\n",
    "    return x.split('--- Forwarded By')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign copy of df_emails to prcess further for preferances/expertise detrmination\n",
    "df_emails0=df_emails\n",
    "# chop email bodies for preferances/experise determination. Notice that we keep these parts for the topics modeling part.\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h1(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h2(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h3(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h4(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h5(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h6(x))\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: h7(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Emails can have forwarded emails below or environment cautions/pricay warnings at the bottom of them. Since this can be the case with\n",
    "# many emails we need to strip these pieces of text to avoid noise in our topic modeling.\n",
    "# we start with defining regex objects that we need for this processing step.\n",
    "\n",
    "import re\n",
    "\n",
    "email_pat = re.compile(\".+@.+\")\n",
    "to_pat = re.compile(\"To:.+\\n\")\n",
    "cc_pat = re.compile(\"cc:.+\\n\")\n",
    "subject_pat = re.compile(\"Subject:.+\\n\")\n",
    "from_pat = re.compile(\"From:.+\\n\")\n",
    "sent_pat = re.compile(\"Sent:.+\\n\")\n",
    "received_pat = re.compile(\"Received:.+\\n\")\n",
    "ctype_pat = re.compile(\"Content-Type:.+\\n\")\n",
    "reply_pat = re.compile(\"Reply- Organization:.+\\n\")\n",
    "date_pat = re.compile(\"Date:.+\\n\")\n",
    "xmail_pat = re.compile(\"X-Mailer:.+\\n\")\n",
    "mimver_pat = re.compile(\"MIME-Version:.+\\n\")\n",
    "dash_pat = re.compile(\"--+.+--+\", re.DOTALL)\n",
    "star_pat = re.compile('\\*\\*+.+\\*\\*+', re.DOTALL)\n",
    "uscore_pat = re.compile(\" __+.+__+\", re.DOTALL)\n",
    "equals_pat = re.compile(\"==+.+==+\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we define a function that takes the body of am email (possibly containing forward email threads and/or \n",
    "# environment warnings/provacy cautions) and returns sole email text (also from emails of a full forward theard\n",
    "# where applicable)\n",
    "\n",
    "def clean_forward_email(email):    \n",
    "    etype=''\n",
    "    if '.nsf' in email:\n",
    "        etype = \".nsf\"\n",
    "    elif '.pst' in email:\n",
    "        etype = '.pst'\n",
    "    email_new = email[email.find(etype)+4:]\n",
    "    email_new = to_pat.sub('', email_new)\n",
    "    email_new = cc_pat.sub('', email_new)\n",
    "    email_new = subject_pat.sub('', email_new)\n",
    "    email_new = from_pat.sub('', email_new)\n",
    "    email_new = sent_pat.sub('', email_new)\n",
    "    email_new = received_pat.sub('', email_new)\n",
    "    email_new = email_pat.sub('', email_new)\n",
    "    email_new = ctype_pat.sub('', email_new)\n",
    "    email_new = reply_pat.sub('', email_new)\n",
    "    email_new = date_pat.sub('', email_new)\n",
    "    email_new = xmail_pat.sub('', email_new)\n",
    "    email_new = mimver_pat.sub('', email_new)\n",
    "    email_new = dash_pat.sub('', email_new)\n",
    "    email_new = star_pat.sub('', email_new)\n",
    "    email_new = uscore_pat.sub('', email_new)\n",
    "    email_new = equals_pat.sub('', email_new)\n",
    "    return email_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process email body column in the full dat aframe containing all emails. These will be used for topic modeling and it seems\n",
    "# perfectly sound to consider full thread as one document with common topic(s)\n",
    "# The reduced table df_emails_mindist need additional step. Namely there we need to determine preferances and for that we need\n",
    "# to be more precise about what each executive writes and what he/she reads\n",
    "df_emails['body']=df_emails['body'].apply(lambda x: clean_forward_email(x))\n",
    "\n",
    "# just to be sure we do the same to df_emails0\n",
    "df_emails0['body']=df_emails0['body'].apply(lambda x: clean_forward_email(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add in vs out box id column to both frames\n",
    "def inoutfunct(x):\n",
    "    result=0\n",
    "    if (x['dist1']==0 or x['dist0']==0):\n",
    "        result= 1\n",
    "    return result\n",
    "df_emails0['inout_id']=df_emails.apply(inoutfunct, axis=1)\n",
    "df_emails['inout_id']=df_emails.apply(inoutfunct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_emails.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails.pkl')\n",
    "df_email0s.to_pickle('/notebooks/LDA models and data/Data Frames and lists/df_emails0.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
